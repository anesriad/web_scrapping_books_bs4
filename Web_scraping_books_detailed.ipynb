{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157ac18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded968b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://books.toscrape.com/catalogue/page-1.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd2bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "#print(response):  = [200] -> meaning that the request was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6fb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb90ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(response): Will give us all the content from the page\n",
    "#Then we introduce Beautiful soup to convert all this into HTML readable content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a36720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "#print(soup) will give the full html code of the page\n",
    "#We use the inspector to analyze the HTML code on the browser\n",
    "#To understand exactly which are the features we should scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b4a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The content is inside ol: ordered list\n",
    "#We use the function 'find' to extract the first element of the ordered list\n",
    "ol = soup.find('ol')\n",
    "#print(ol) gives the whole content inside the ordered list but we'll need to filter the content we need\n",
    "#What we need is the name of the book, the link and reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b19c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_all: is used to find all the content inside 'article' and specifically inside class: 'product_pod'\n",
    "#We add '_' to class => class_ : to differentiate it from class in Python\n",
    "articles = ol.find_all('article', class_ = 'product_pod')\n",
    "#print(articles) will give us all the 'article' content which is related to each book on the page number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6839fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A Light in the Attic', 51.77, 'Three'], ['Tipping the Velvet', 53.74, 'One'], ['Soumission', 50.1, 'One'], ['Sharp Objects', 47.82, 'Four'], ['Sapiens: A Brief History of Humankind', 54.23, 'Five'], ['The Requiem Red', 22.65, 'One'], ['The Dirty Little Secrets of Getting Your Dream Job', 33.34, 'Four'], ['The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', 17.93, 'Three'], ['The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', 22.6, 'Four'], ['The Black Maria', 52.15, 'One'], ['Starving Hearts (Triangular Trade Trilogy, #1)', 13.99, 'Two'], [\"Shakespeare's Sonnets\", 20.66, 'Four'], ['Set Me Free', 17.46, 'Five'], [\"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", 52.29, 'Five'], ['Rip it Up and Start Again', 35.02, 'Five'], ['Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', 57.25, 'Three'], ['Olio', 23.88, 'One'], ['Mesaerion: The Best Science Fiction Stories 1800-1849', 37.59, 'One'], ['Libertarianism for Beginners', 51.33, 'Two'], [\"It's Only the Himalayas\", 45.17, 'Two']]\n"
     ]
    }
   ],
   "source": [
    "books = [] #empty list that will contain the output of the function\n",
    "#Next we are going to create a function that extracts the information we seek\n",
    "#To get the title of the book we should going inside 'img' then the text is inside 'alt'\n",
    "#star reviews is inside of 'p' (paragraph)\n",
    "for article in articles:\n",
    "    image = article.find('img')\n",
    "    title = image.attrs['alt'] #'alt' is an attribute, therefore, we use 'attrs' function\n",
    "    #print(title): to get all the titles\n",
    "    star = article.find('p')\n",
    "    star = star['class'][1]\n",
    "    #print(star): to get the reviews. Howver, we only need the number of stars so we can skip the first part of the review\n",
    "    price = article.find('p', class_ = 'price_color').text\n",
    "    #print(price): will return all the content inside p and we only want the price\n",
    "    #so we add '.text' at the end\n",
    "    price = float(price[1:]) #This will remove the pound sign and convert it into a float instead of char\n",
    "    books.append([title, price, star])\n",
    "print(books) #prints a list of the books on the first page with title, price, stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a19ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
